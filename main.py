#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ç½‘é¡µå†…å®¹é€’å½’é˜…è¯»å™¨ - ä¸»ç¨‹åºå…¥å£

ç”¨æ³•:
    python main.py <URL> [é€‰é¡¹]

ç¤ºä¾‹:
    python main.py https://example.com
    python main.py https://example.com --depth 3 --max-pages 100
    python main.py https://example.com --format json --output ./my_output
"""

import argparse
import asyncio
import sys
import os
import io

# å¼ºåˆ¶è®¾ç½®æ ‡å‡†è¾“å‡ºä¸º UTF-8
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')


# å°†å½“å‰ç›®å½•æ·»åŠ åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from crawler import WebReader
from config import DEFAULT_CONFIG


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description='ç½‘é¡µå†…å®¹é€’å½’é˜…è¯»å™¨ - é€’å½’æŠ“å–ç½‘é¡µå†…å®¹å¹¶ä¿å­˜',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  %(prog)s https://example.com
  %(prog)s https://example.com --depth 2 --max-pages 50
  %(prog)s https://blog.example.com --format markdown --same-domain
        """
    )
    
    parser.add_argument(
        'url',
        help='èµ·å§‹URL (å¿…é¡»åŒ…å« http:// æˆ– https://)'
    )
    
    parser.add_argument(
        '-d', '--depth',
        type=int,
        default=DEFAULT_CONFIG['max_depth'],
        help=f'æœ€å¤§é€’å½’æ·±åº¦ (é»˜è®¤: {DEFAULT_CONFIG["max_depth"]})'
    )
    
    parser.add_argument(
        '-m', '--max-pages',
        type=int,
        default=DEFAULT_CONFIG['max_pages'],
        help=f'æœ€å¤§æŠ“å–é¡µé¢æ•° (é»˜è®¤: {DEFAULT_CONFIG["max_pages"]})'
    )
    
    parser.add_argument(
        '-f', '--format',
        choices=['markdown', 'json', 'txt'],
        default=DEFAULT_CONFIG['output_format'],
        help=f'è¾“å‡ºæ ¼å¼ (é»˜è®¤: {DEFAULT_CONFIG["output_format"]})'
    )
    
    parser.add_argument(
        '-o', '--output',
        default=DEFAULT_CONFIG['output_dir'],
        help=f'è¾“å‡ºç›®å½• (é»˜è®¤: {DEFAULT_CONFIG["output_dir"]})'
    )
    
    parser.add_argument(
        '--delay',
        type=float,
        default=DEFAULT_CONFIG['delay'],
        help=f'è¯·æ±‚é—´éš”ç§’æ•° (é»˜è®¤: {DEFAULT_CONFIG["delay"]})'
    )
    
    parser.add_argument(
        '--timeout',
        type=int,
        default=DEFAULT_CONFIG['timeout'],
        help=f'è¯·æ±‚è¶…æ—¶ç§’æ•° (é»˜è®¤: {DEFAULT_CONFIG["timeout"]})'
    )
    
    parser.add_argument(
        '--no-same-domain',
        action='store_true',
        help='å…è®¸æŠ“å–è·¨åŸŸé“¾æ¥ (é»˜è®¤: ä»…åŒåŸŸå)'
    )
    
    parser.add_argument(
        '-v', '--verbose',
        action='store_true',
        help='æ˜¾ç¤ºè¯¦ç»†è¾“å‡º'
    )
    
    return parser.parse_args()


def validate_url(url: str) -> bool:
    """éªŒè¯URLæ ¼å¼"""
    if not url.startswith(('http://', 'https://')):
        print(f"âŒ é”™è¯¯: URLå¿…é¡»ä»¥ http:// æˆ– https:// å¼€å¤´")
        print(f"   æ‚¨è¾“å…¥çš„æ˜¯: {url}")
        return False
    return True


async def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()
    
    # éªŒè¯URL
    if not validate_url(args.url):
        sys.exit(1)
    
    # æ„å»ºé…ç½®
    config = {
        'max_depth': args.depth,
        'max_pages': args.max_pages,
        'output_format': args.format,
        'output_dir': args.output,
        'delay': args.delay,
        'timeout': args.timeout,
        'same_domain_only': not args.no_same_domain,
    }
    
    # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    print("\n" + "=" * 60)
    print("ğŸ“– ç½‘é¡µå†…å®¹é€’å½’é˜…è¯»å™¨")
    print("=" * 60)
    print(f"ğŸŒ ç›®æ ‡URL: {args.url}")
    print(f"ğŸ“Š é…ç½®:")
    print(f"   - æœ€å¤§æ·±åº¦: {config['max_depth']}")
    print(f"   - æœ€å¤§é¡µé¢æ•°: {config['max_pages']}")
    print(f"   - è¾“å‡ºæ ¼å¼: {config['output_format']}")
    print(f"   - è¾“å‡ºç›®å½•: {config['output_dir']}")
    print(f"   - è¯·æ±‚é—´éš”: {config['delay']}ç§’")
    print(f"   - ä»…åŒåŸŸå: {'æ˜¯' if config['same_domain_only'] else 'å¦'}")
    print("=" * 60)
    
    # åˆ›å»ºçˆ¬è™«å¹¶å¼€å§‹æŠ“å–
    reader = WebReader(config)
    
    try:
        await reader.crawl(args.url)
        reader.save_results()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨ä¿å­˜å·²æŠ“å–çš„å†…å®¹...")
        if reader.results:
            reader.save_results()
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)
    
    print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨!\n")


if __name__ == '__main__':
    # Windows ä¸‹é€šå¸¸ä¸éœ€è¦æ‰‹åŠ¨è®¾ç½® EventLoopPolicyï¼ŒPython 3.8+ é»˜è®¤ä½¿ç”¨ ProactorEventLoop
    # å¦‚æœé‡åˆ° "NotImplementedError"ï¼Œè¯·ç¡®ä¿ä½¿ç”¨çš„æ˜¯ ProactorEventLoop
    # if sys.platform == 'win32':
    #     asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    
    asyncio.run(main())
